{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef86023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crowd/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>dataset</th>\n",
       "      <th>eval_type</th>\n",
       "      <th>data_setting</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>seed</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tasd</td>\n",
       "      <td>crowd-tasd</td>\n",
       "      <td>test</td>\n",
       "      <td>orig-o</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.3394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tasd</td>\n",
       "      <td>crowd-tasd</td>\n",
       "      <td>test</td>\n",
       "      <td>orig-o</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5187</td>\n",
       "      <td>0.5068</td>\n",
       "      <td>0.3502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tasd</td>\n",
       "      <td>crowd-tasd</td>\n",
       "      <td>test</td>\n",
       "      <td>orig-o</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5246</td>\n",
       "      <td>0.5206</td>\n",
       "      <td>0.3555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tasd</td>\n",
       "      <td>crowd-tasd</td>\n",
       "      <td>test</td>\n",
       "      <td>orig-o</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>0.4985</td>\n",
       "      <td>0.4914</td>\n",
       "      <td>0.3320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tasd</td>\n",
       "      <td>crowd-tasd</td>\n",
       "      <td>test</td>\n",
       "      <td>orig-o</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5157</td>\n",
       "      <td>0.5084</td>\n",
       "      <td>0.3474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task     dataset eval_type data_setting learning-rate batch_size epochs  \\\n",
       "0  tasd  crowd-tasd      test       orig-o        0.0001         16     15   \n",
       "1  tasd  crowd-tasd      test       orig-o        0.0001         16     15   \n",
       "2  tasd  crowd-tasd      test       orig-o        0.0001         16     15   \n",
       "3  tasd  crowd-tasd      test       orig-o        0.0001         16     15   \n",
       "4  tasd  crowd-tasd      test       orig-o        0.0001         16     15   \n",
       "\n",
       "  seed  f1-micro  f1-macro  accuracy  \n",
       "0   10    0.5068    0.5016    0.3394  \n",
       "1   15    0.5187    0.5068    0.3502  \n",
       "2   20    0.5246    0.5206    0.3555  \n",
       "3   25    0.4985    0.4914    0.3320  \n",
       "4    5    0.5157    0.5084    0.3474  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "col_names = ['task', 'dataset', 'eval_type', 'data_setting', 'learning-rate', 'batch_size', 'epochs', 'seed', 'f1-micro', 'f1-macro', 'accuracy']\n",
    "runs = []\n",
    "\n",
    "RESULTS_PATH = 'Crowd/' # Experts, LLM\n",
    "folder_names = [folder for folder in os.listdir(os.path.join(RESULTS_PATH)) if os.path.isdir(os.path.join(RESULTS_PATH, folder)) and folder != '.ipynb_checkpoints']\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    try:\n",
    "        cond_parameters = folder_name.split('_')\n",
    "        if cond_parameters[0] == 'acd':\n",
    "            df = pd.read_csv(os.path.join(RESULTS_PATH, folder_name, 'metrics_asp.tsv'), sep = '\\t')\n",
    "        elif cond_parameters[0] == 'tasd':\n",
    "            df = pd.read_csv(os.path.join(RESULTS_PATH, folder_name, 'metrics_phrases.tsv'), sep = '\\t')\n",
    "        else:\n",
    "            df = pd.read_csv(os.path.join(RESULTS_PATH, folder_name, 'metrics_asp_pol.tsv'), sep = '\\t')\n",
    "                    \n",
    "        df = df.set_index(df.columns[0])\n",
    "\n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Macro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'accuracy'])\n",
    "        runs.append(cond_parameters)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "results_all = pd.DataFrame(runs, columns = col_names)\n",
    "results_all[\"f1-micro\"] = pd.to_numeric(results_all[\"f1-micro\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "config_cols = [\"dataset\", \"data_setting\", \"eval_type\", \"learning_rate\", \"epoch\"]\n",
    "\n",
    "# 2. Mittelung von 'orig-o' + 'orig-d' fÃ¼r jeden Seed + weitere Konfigs\n",
    "# -> z. B. [\"dataset\", \"task\", \"eval_type\", \"seed\", \"learning_rate\", \"epoch\"]\n",
    "group_cols_for_merge = [col for col in config_cols if col != 'data_setting'] + ['task', 'batch_size']\n",
    "if 'seed' in results_all.columns:\n",
    "    group_cols_for_merge.append('seed')\n",
    "print(RESULTS_PATH)\n",
    "results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "657bbcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experts/ tasd\n",
      "Method: MvP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_setting</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>eval_type</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orig-o</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>64.01</td>\n",
       "      <td>59.42</td>\n",
       "      <td>0.47074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_setting learning-rate batch_size epochs eval_type  f1-micro  f1-macro  \\\n",
       "0       orig-o        0.0001         16     15      test     64.01     59.42   \n",
       "\n",
       "   accuracy  \n",
       "0   0.47074  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "task = 'tasd'\n",
    "data_setting = 'orig-o'\n",
    "eval_count = 5\n",
    "eval_type = 'test'\n",
    "\n",
    "if eval_type == 'dev':\n",
    "    eval_count = 1\n",
    "else:\n",
    "    eval_count = 5\n",
    "\n",
    "config_cols = [\"data_setting\", 'learning-rate', 'batch_size', 'epochs', \"eval_type\"]\n",
    "\n",
    "# Filtere nach den relevanten Parametern\n",
    "df_filtered = results_all[np.logical_and.reduce([\n",
    "    results_all['task'] == task, \n",
    "    results_all['data_setting'] == data_setting,\n",
    "    results_all['eval_type'] == eval_type\n",
    "])]\n",
    "\n",
    "# Gruppiere und filtere auf Gruppen mit genau eval_count EintrÃ¤gen\n",
    "df_grouped = df_filtered.groupby(config_cols).filter(lambda x: len(x) == eval_count)\n",
    "\n",
    "# Berechne dann den Durchschnitt nur Ã¼ber diese Gruppen\n",
    "df_best_per_lang = df_grouped.groupby(config_cols)[[\"f1-micro\", \"f1-macro\", \"accuracy\"]].mean().reset_index()\n",
    "\n",
    "df_best_per_lang['f1-micro'] = df_best_per_lang['f1-micro'].apply(lambda x: round(x*100,2))\n",
    "df_best_per_lang['f1-macro'] = df_best_per_lang['f1-macro'].apply(lambda x: round(x*100,2))\n",
    "print(RESULTS_PATH, task)\n",
    "print(\"Method: MvP\")\n",
    "df_best_per_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77267e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   task   dataset eval_type data_setting learning-rate batch_size epochs seed  \\\n",
      "0  tasd  llm-tasd      test       orig-o        0.0001         16     15   10   \n",
      "1  tasd  llm-tasd      test       orig-o        0.0001         16     15   15   \n",
      "2  tasd  llm-tasd      test       orig-o        0.0001         16     15   20   \n",
      "3  tasd  llm-tasd      test       orig-o        0.0001         16     15   25   \n",
      "4  tasd  llm-tasd      test       orig-o        0.0001         16     15    5   \n",
      "\n",
      "   train_runtime  gpu_util  \n",
      "0    3523.328309    11.781  \n",
      "1    3523.546426    11.781  \n",
      "2    3524.520263    11.781  \n",
      "3    3527.028939    11.781  \n",
      "4    3584.843706    11.906  \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "import pandas as pd\n",
    "\n",
    "# Only keep relevant columns\n",
    "col_names = ['task', 'dataset', 'eval_type', 'data_setting', 'learning-rate', 'batch_size', 'epochs', 'seed', 'train_runtime', 'gpu_util']\n",
    "runs = []\n",
    "\n",
    "RESULTS_PATH = 'LLM/'\n",
    "folder_names = [\n",
    "    folder for folder in os.listdir(RESULTS_PATH) \n",
    "    if os.path.isdir(os.path.join(RESULTS_PATH, folder)) \n",
    "    and folder != '.ipynb_checkpoints'\n",
    "]\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    try:\n",
    "        cond_parameters = folder_name.split('_')\n",
    "        \n",
    "        # Load config.json\n",
    "        config_path = os.path.join(RESULTS_PATH, folder_name, 'config.json')\n",
    "        with open(config_path, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        # Append train_runtime and gpu_util if present\n",
    "        cond_parameters.append(config.get(\"train_runtime\", None))\n",
    "        cond_parameters.append(config.get(\"gpu_util\", None))\n",
    "\n",
    "        runs.append(cond_parameters)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {folder_name}: {e}\")\n",
    "        pass\n",
    "\n",
    "# Build DataFrame\n",
    "results_all = pd.DataFrame(runs, columns=col_names)\n",
    "\n",
    "print(results_all.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35eea305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM/\n",
      "Method: MvP\n",
      "  data_setting eval_type learning-rate epochs train_runtime  gpu_util\n",
      "0       orig-o      test        0.0001     15         00:58     11.81\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "task = 'tasd'\n",
    "data_setting = 'orig-o'\n",
    "eval_count = 5\n",
    "eval_type = 'test'\n",
    "\n",
    "if eval_type == 'dev':\n",
    "    eval_count = 1\n",
    "else:\n",
    "    eval_count = 5\n",
    "\n",
    "# ðŸš¨ remove 'train_runtime' and 'gpu_util' from grouping columns\n",
    "config_cols = [\"data_setting\", \"eval_type\", \"learning-rate\", \"epochs\"]\n",
    "\n",
    "# Filter relevant rows\n",
    "df_filtered = results_all[np.logical_and.reduce([\n",
    "    results_all['task'] == task, \n",
    "    results_all['data_setting'] == data_setting,\n",
    "    results_all['eval_type'] == eval_type\n",
    "])]\n",
    "\n",
    "# Keep only groups with exactly eval_count entries\n",
    "df_grouped = df_filtered.groupby(config_cols).filter(lambda x: len(x) == eval_count)\n",
    "\n",
    "# Aggregate runtime + gpu util\n",
    "df_best_per_lang = (\n",
    "    df_grouped.groupby(config_cols)[[\"train_runtime\", \"gpu_util\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Convert train_runtime (seconds) â†’ hh:mm format\n",
    "df_best_per_lang['train_runtime'] = df_best_per_lang['train_runtime'].apply(\n",
    "    lambda x: f\"{int(x//3600):02d}:{int((x%3600)//60):02d}\"\n",
    ")\n",
    "\n",
    "# Round gpu_util to 2 decimals\n",
    "df_best_per_lang['gpu_util'] = df_best_per_lang['gpu_util'].round(2)\n",
    "\n",
    "print(RESULTS_PATH)\n",
    "print(\"Method: MvP\")\n",
    "print(df_best_per_lang)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
