{
    "model_name": "meta-llama/Llama-3.1-8B",
    "task": "tasd",
    "data_setting": "orig",
    "dataset": "experts/tasd",
    "per_device_train_batch_size": 16,
    "gradient_accumulation_steps": 1,
    "learning_rate": 0.0002,
    "num_train_epochs": 6,
    "eval_type": "test",
    "lr_scheduler_type": "linear",
    "seed": 15,
    "used_memory": 14.367,
    "used_memory_for_lora": 7.23,
    "temperature": 0,
    "max_tokens": 200,
    "top_k": -1,
    "top_p": 1,
    "training_time": "0:38:51.183261",
    "eval_time": 679.2816250324249
}